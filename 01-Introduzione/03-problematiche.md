# Modulo 1 - Problematiche della Programmazione Concorrente

## Indice
- [Introduzione](#introduzione)
- [Race Condition](#race-condition)
- [Deadlock](#deadlock)
- [Starvation](#starvation)
- [Livelock](#livelock)
- [AtomicitÃ  delle Operazioni](#atomicitÃ -delle-operazioni)
- [Priority Inversion](#priority-inversion)
- [Problemi Classici](#problemi-classici)
- [Tecniche di Prevenzione](#tecniche-di-prevenzione)

---

## Introduzione

La programmazione concorrente introduce una serie di problematiche che non esistono nei programmi sequenziali. Questi problemi derivano principalmente da:
- Accesso condiviso a risorse
- Timing non deterministico
- Interleaving imprevedibile
- Mancanza di sincronizzazione

Comprendere questi problemi Ã¨ essenziale per scrivere programmi concorrenti corretti.

---

## Race Condition

### Definizione

Una **race condition** (condizione di corsa) si verifica quando il comportamento di un programma dipende dalla sequenza temporale o dall'interleaving di thread/processi multipli che accedono a risorse condivise. Il risultato finale dipende da quale thread "vince la corsa" nell'accedere alla risorsa.

### PerchÃ© si chiamano "Race Condition"?

Il termine deriva dal fatto che piÃ¹ thread/processi "gareggiano" (race) per accedere alla stessa risorsa, e il risultato dipende da chi arriva primo. Ãˆ come una corsa dove l'ordine di arrivo non Ã¨ predicibile e cambia ogni volta.

### Caratteristiche delle Race Condition

1. **Non Determinismo**: Esecuzioni diverse producono risultati diversi
2. **Difficile da Riprodurre**: Il bug puÃ² apparire raramente e casualmente
3. **Dipendenza dal Timing**: Influenzato da carico CPU, scheduling, velocitÃ  I/O
4. **Heisenbug**: Il bug scompare quando si cerca di debuggare (a causa di breakpoint che alterano il timing)

### Esempio Classico: Incremento Non Atomico

```python
# Codice Python con race condition
import threading

counter = 0

def increment():
    global counter
    for _ in range(100000):
        counter += 1  # NON Ã¨ atomico!

# Due thread
t1 = threading.Thread(target=increment)
t2 = threading.Thread(target=increment)

t1.start()
t2.start()
t1.join()
t2.join()

print(f"Counter: {counter}")
# Risultato atteso: 200000
# Risultato reale: spesso < 200000 (es. 137529)
```

### PerchÃ© Succede?

L'operazione `counter += 1` appare semplice nel codice, ma a livello di istruzioni macchina si traduce in **tre operazioni distinte**:

```assembly
1. LOAD counter into register    ; Legge valore dalla memoria
2. ADD 1 to register             ; Incrementa nel registro CPU
3. STORE register to counter     ; Scrive valore in memoria
```

Questo Ã¨ il problema: tra il LOAD e lo STORE, il valore in memoria puÃ² essere modificato da un altro thread!

**Interleaving problematico (scenario A):**
```
Tempo  Thread 1          Thread 2          counter (memoria)
  0    LOAD (0)                            0
  1                      LOAD (0)          0
  2    ADD (1)                             0
  3                      ADD (1)           0
  4    STORE (1)                           1
  5                      STORE (1)         1  â† Dovrebbe essere 2!
```

In questo scenario, entrambi i thread leggono 0, incrementano a 1, e scrivono 1. Un incremento Ã¨ "perso".

**Interleaving problematico (scenario B - ancora peggio):**
```
Tempo  Thread 1          Thread 2          counter
  0    LOAD (0)                            0
  1    ADD (1)                             0
  2                      LOAD (0)          0
  3    STORE (1)                           1
  4                      ADD (1)           1
  5                      STORE (1)         1  â† Ancora 1!
```

**Interleaving corretto (con fortuna):**
```
Tempo  Thread 1          Thread 2          counter
  0    LOAD (0)                            0
  1    ADD (1)                             0
  2    STORE (1)                           1
  3                      LOAD (1)          1  â† Legge valore aggiornato
  4                      ADD (1)           1
  5                      STORE (2)         2  âœ“ Corretto!
```

Il problema Ã¨ che **non possiamo controllare quale scenario si verifica**. Dipende completamente dallo scheduler del sistema operativo.

### Visualizzazione

```
Tempo â†’
T1: â”€LOAD(0)â”€ADDâ”€STORE(1)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
T2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€LOAD(0)â”€ADDâ”€STORE(1)â”€
                                  â†‘
                           Valore perso!
```

### Race Condition nei Banking System

```python
# Esempio realistico: trasferimento bancario
class BankAccount:
    def __init__(self, balance):
        self.balance = balance
    
    def transfer(self, amount, to_account):
        # RACE CONDITION!
        if self.balance >= amount:
            self.balance -= amount
            to_account.balance += amount
            return True
        return False

# Due thread trasferiscono contemporaneamente
account_a = BankAccount(100)
account_b = BankAccount(50)

def transfer_money():
    account_a.transfer(80, account_b)

t1 = threading.Thread(target=transfer_money)
t2 = threading.Thread(target=transfer_money)
# Entrambi potrebbero passare il check del balance!
```

### Soluzioni

#### 1. Lock (Mutex)

```python
import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100000):
        with lock:  # Sezione critica
            counter += 1

# Ora Ã¨ corretto!
```

#### 2. Operazioni Atomiche

```python
from threading import Lock
import threading

class AtomicCounter:
    def __init__(self):
        self.value = 0
        self._lock = Lock()
    
    def increment(self):
        with self._lock:
            self.value += 1
            return self.value

counter = AtomicCounter()

def worker():
    for _ in range(100000):
        counter.increment()
```

#### 3. Atomic Types (Java)

```java
import java.util.concurrent.atomic.AtomicInteger;

class Counter {
    private AtomicInteger count = new AtomicInteger(0);
    
    public void increment() {
        count.incrementAndGet();  // Atomico!
    }
    
    public int getCount() {
        return count.get();
    }
}
```

---

## Deadlock

### Definizione

Un **deadlock** (stallo critico) si verifica quando due o piÃ¹ processi/thread sono bloccati indefinitamente, ognuno in attesa che l'altro rilasci una risorsa. Nessuno puÃ² procedere, creando un blocco permanente del sistema.

### Analogia della Vita Reale

Immagina un incrocio stradale a 4 vie dove:
- 4 auto arrivano contemporaneamente da 4 direzioni diverse
- Ogni auto occupa metÃ  strada (la sua risorsa)
- Ogni auto deve attraversare l'altra metÃ  (la risorsa dell'auto successiva)
- Nessuna auto puÃ² procedere senza che un'altra si muova
- **Risultato: Deadlock!** Tutte le auto sono bloccate per sempre.

```
        â”‚ â†“ â”‚
    â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€
  â†’     â”‚ â— â”‚     â†
    â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€
        â”‚ â†‘ â”‚
    Tutte bloccate!
```

### PerchÃ© Ã¨ un Problema Grave?

1. **Blocco Permanente**: A differenza di un rallentamento, il sistema non si riprende mai da solo
2. **Sprechi di Risorse**: Le risorse bloccate non possono essere usate da altri
3. **Cascading Effects**: Un deadlock puÃ² propagarsi e bloccare altri processi
4. **Difficile da Rilevare**: PuÃ² non essere immediatamente evidente che c'Ã¨ un deadlock
5. **Recovery Complesso**: Richiede intervento esterno (terminare processi, restart)

### Esempio Classico: Filosofi a Cena

```
     F1
    /  \
  c1    c5
  |      |
 F5      F2
  |      |
  c4    c2
    \  /
     F3
```

Ogni filosofo ha bisogno di due bacchette per mangiare.

```python
import threading
import time

# 5 bacchette (lock)
chopsticks = [threading.Lock() for _ in range(5)]

def philosopher(id):
    left = id
    right = (id + 1) % 5
    
    while True:
        # Pensa
        time.sleep(0.1)
        
        # Prende bacchetta sinistra
        chopsticks[left].acquire()
        print(f"Philosopher {id} got left chopstick")
        
        # Prende bacchetta destra
        chopsticks[right].acquire()
        print(f"Philosopher {id} got right chopstick")
        
        # Mangia
        print(f"Philosopher {id} is eating")
        time.sleep(0.1)
        
        # Rilascia
        chopsticks[right].release()
        chopsticks[left].release()

# Se tutti prendono la bacchetta sinistra contemporaneamente â†’ DEADLOCK!
```

### Condizioni di Coffman

Il teorema di Coffman (1971) stabilisce che un deadlock puÃ² verificarsi **SOLO se sono presenti TUTTE E 4 le seguenti condizioni contemporaneamente**:

#### 1. Mutua Esclusione (Mutual Exclusion)
**Definizione**: Almeno una risorsa deve essere non condivisibile - puÃ² essere usata da un solo processo alla volta.

**Esempio**: 
```
Stampante: puÃ² stampare un documento alla volta
Lock/Mutex: puÃ² essere acquisito da un solo thread
File in scrittura: solo un processo puÃ² scrivere
```

**Non Ã¨ mutua esclusione**:
```
File in lettura: piÃ¹ processi possono leggere simultaneamente
Memoria read-only: infiniti lettori
```

#### 2. Hold and Wait (Possesso e Attesa)
**Definizione**: Un processo che giÃ  possiede almeno una risorsa sta aspettando di acquisire altre risorse possedute da altri processi.

**Esempio**:
```
Thread A: 
  - Possiede: Lock1 âœ“
  - Aspetta: Lock2 (posseduto da Thread B)

Thread B:
  - Possiede: Lock2 âœ“
  - Aspetta: Lock1 (posseduto da Thread A)
```

**Visualizzazione**:
```
Thread A: [â–ˆ Lock1] â”€â”€waitingâ”€â”€> Lock2
Thread B: [â–ˆ Lock2] â”€â”€waitingâ”€â”€> Lock1
```

#### 3. No Preemption (Non Prelazione)
**Definizione**: Le risorse non possono essere forzatamente rimosse da un processo che le possiede. Devono essere rilasciate volontariamente.

**Esempio**:
```python
# Il sistema operativo NON puÃ² fare:
force_release(thread_a, lock1)  # Non permesso!

# Il thread deve rilasciare volontariamente:
lock1.release()  # Solo il possessore puÃ² farlo
```

**PerchÃ© questa condizione?**
- Rilasciare forzatamente puÃ² lasciare dati in stato inconsistente
- Il processo potrebbe essere nel mezzo di un'operazione critica
- Esempio: se interrompo durante una transazione bancaria, i conti potrebbero risultare sbilanciati

#### 4. Attesa Circolare (Circular Wait)
**Definizione**: Esiste un insieme di processi {P0, P1, ..., Pn} dove:
- P0 aspetta una risorsa posseduta da P1
- P1 aspetta una risorsa posseduta da P2
- ...
- Pn aspetta una risorsa posseduta da P0

**Visualizzazione del ciclo**:
```
    P1 â”€â”€holdsâ”€â”€> R1 â”€â”€needed byâ”€â”€> P2
    â†‘                                 â”‚
    â”‚                                 â”‚
needed by                          holds
    â”‚                                 â†“
    P4 <â”€â”€needed byâ”€â”€ R3 <â”€â”€holdsâ”€â”€ P3
    â”‚                                 â†‘
    â””â”€â”€holdsâ”€â”€> R4 â”€â”€needed byâ”€â”€â”€â”€â”€â”€â”€â”˜

Ciclo: P1 â†’ P2 â†’ P3 â†’ P4 â†’ P1
```

**Esempio concreto (database)**:
```
Transaction T1: Lock(Account_A) â†’ waiting for Lock(Account_B)
Transaction T2: Lock(Account_B) â†’ waiting for Lock(Account_C)
Transaction T3: Lock(Account_C) â†’ waiting for Lock(Account_A)

Ciclo completo: T1 â†’ T2 â†’ T3 â†’ T1 (DEADLOCK!)
```

### Importanza delle 4 Condizioni

**Rompere ANCHE SOLO UNA delle 4 condizioni previene il deadlock!**

Questo Ã¨ fondamentale per le strategie di prevenzione:
- Elimina mutua esclusione â†’ usa risorse condivisibili quando possibile
- Elimina hold-and-wait â†’ acquisisci tutte le risorse in una volta
- Permetti preemption â†’ forza il rilascio con timeout
- Elimina attesa circolare â†’ imponi ordinamento nell'acquisizione

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tutte e 4 condizioni presenti       â”‚
â”‚ â†“                                   â”‚
â”‚ DEADLOCK POSSIBILE                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Almeno 1 condizione assente         â”‚
â”‚ â†“                                   â”‚
â”‚ DEADLOCK IMPOSSIBILE âœ“              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Esempio: Lock Classico

```python
import threading

lock_a = threading.Lock()
lock_b = threading.Lock()

def thread1():
    with lock_a:
        print("Thread 1: acquired lock_a")
        time.sleep(0.1)  # Simula lavoro
        with lock_b:
            print("Thread 1: acquired lock_b")

def thread2():
    with lock_b:  # Ordine inverso!
        print("Thread 2: acquired lock_b")
        time.sleep(0.1)
        with lock_a:
            print("Thread 2: acquired lock_a")

# DEADLOCK!
t1 = threading.Thread(target=thread1)
t2 = threading.Thread(target=thread2)
t1.start()
t2.start()
```

**Diagramma del deadlock:**
```
Thread 1: â”€â”¬â”€ lock_a â”€â”¬â”€ waiting for lock_b â”€â”
           â”‚          â”‚                       â”‚
Thread 2: â”€â”´â”€ lock_b â”€â”´â”€ waiting for lock_a â†â”˜
           â†‘           â†‘
        T=0ms       T=100ms
```

### Strategie di Prevenzione

#### 1. Lock Ordering

Imporre un ordine globale nell'acquisizione dei lock:

```python
def thread1():
    # Acquisisce sempre in ordine: lock_a poi lock_b
    with lock_a:
        with lock_b:
            do_work()

def thread2():
    # Stesso ordine!
    with lock_a:
        with lock_b:
            do_work()
```

#### 2. Try-Lock con Timeout

```python
def thread1():
    while True:
        if lock_a.acquire(timeout=1):
            try:
                if lock_b.acquire(timeout=1):
                    try:
                        do_work()
                        break
                    finally:
                        lock_b.release()
                else:
                    # Timeout su lock_b, rilascia lock_a
                    lock_a.release()
                    time.sleep(random.random())  # Backoff
            except:
                lock_a.release()
                raise
```

#### 3. Lock Hierarchy

```python
class Account:
    _id_counter = 0
    
    def __init__(self, balance):
        self.id = Account._id_counter
        Account._id_counter += 1
        self.balance = balance
        self.lock = threading.Lock()

def transfer(from_account, to_account, amount):
    # Acquisisce sempre in ordine di ID
    first = from_account if from_account.id < to_account.id else to_account
    second = to_account if from_account.id < to_account.id else from_account
    
    with first.lock:
        with second.lock:
            from_account.balance -= amount
            to_account.balance += amount
```

#### 4. Deadlock Detection

```bash
# Linux - rilevamento deadlock thread
gdb -p <pid>
(gdb) info threads
(gdb) thread apply all bt

# Java - thread dump
jstack <pid>
# Cerca "Found one Java-level deadlock"
```

---

## Starvation

### Definizione

**Starvation** (inedia/denutrizione) si verifica quando un thread/processo non riesce mai (o per un tempo indefinitamente lungo) ad ottenere le risorse necessarie per progredire, nonostante le risorse siano disponibili e assegnate ad altri processi.

### Differenza tra Deadlock e Starvation

Ãˆ importante distinguere questi due concetti:

**Deadlock:**
```
Processo A: bloccato per sempre âš«
Processo B: bloccato per sempre âš«
Nessuno puÃ² progredire
Sistema completamente fermo
```

**Starvation:**
```
Processo A: esegue â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Processo B: esegue â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Processo C: non esegue mai âš« (starved)
Il sistema funziona, ma C Ã¨ "dimenticato"
```

**Tabella comparativa:**

| Aspetto | Deadlock | Starvation |
|---------|----------|------------|
| Processi bloccati | Tutti nel ciclo | Solo alcuni |
| Sistema funziona? | No, fermo | SÃ¬, ma ingiusto |
| Risorse disponibili? | No, tutte bloccate | SÃ¬, ma date ad altri |
| Causa | Attesa circolare | Scheduling iniquo |
| Durata | Permanente | Indefinita (ma teoricamente risolvibile) |

### Cause Comuni di Starvation

#### 1. Priority-Based Scheduling
Processi ad alta prioritÃ  monopolizzano la CPU:

```
Priority Queue:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ P1 (priority 10) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚  â† Sempre eseguiti
â”‚ P2 (priority 10) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚
â”‚ P3 (priority 9)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚
â”‚ ...                         â”‚
â”‚ P99 (priority 1) âš« STARVED â”‚  â† Mai eseguito
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2. Lock Contention
Thread "sfortunati" che non riescono mai ad acquisire un lock:

```
Lock acquisito da:
Thread A â–ˆâ–ˆâ–ˆâ–ˆ  Thread B â–ˆâ–ˆâ–ˆâ–ˆ  Thread A â–ˆâ–ˆâ–ˆâ–ˆ  Thread B â–ˆâ–ˆâ–ˆâ–ˆ
Thread C continua ad aspettare... â³â³â³â³â³ (STARVED)
```

#### 3. Readers-Writers Unfairness
Flusso continuo di lettori blocca gli scrittori:

```
Time:  0ms     1000ms    2000ms    3000ms
Readers: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Writer:  â³â³â³â³â³â³â³â³â³â³â³â³ (waiting forever)
```

#### 4. Resource Allocation
Risorse sempre assegnate agli stessi processi:

```
CPU allocation:
P1: 50% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
P2: 50% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
P3:  0% âš« (STARVED - nessuna CPU time)
```

### Esempio: Priority Starvation

```python
import threading
import queue
import time

class PriorityTask:
    def __init__(self, priority, task):
        self.priority = priority
        self.task = task
    
    def __lt__(self, other):
        return self.priority > other.priority  # Higher priority first

task_queue = queue.PriorityQueue()

def worker():
    while True:
        task = task_queue.get()
        print(f"Executing task with priority {task.priority}")
        task.task()
        task_queue.task_done()

# Worker thread
threading.Thread(target=worker, daemon=True).start()

# Aggiungi task ad alta prioritÃ  continuamente
for i in range(100):
    task_queue.put(PriorityTask(priority=10, task=lambda: time.sleep(0.1)))
    
# Questo task a bassa prioritÃ  potrebbe non essere mai eseguito!
task_queue.put(PriorityTask(priority=1, task=lambda: print("LOW PRIORITY")))
```

### Readers-Writers Starvation

```python
import threading

class ReadersWriters:
    def __init__(self):
        self.readers = 0
        self.lock = threading.Lock()
        self.write_lock = threading.Lock()
    
    def start_read(self):
        with self.lock:
            self.readers += 1
            if self.readers == 1:
                self.write_lock.acquire()  # Block writers
    
    def end_read(self):
        with self.lock:
            self.readers -= 1
            if self.readers == 0:
                self.write_lock.release()
    
    def start_write(self):
        self.write_lock.acquire()  # Se lettori continui â†’ STARVATION!
    
    def end_write(self):
        self.write_lock.release()
```

**Problema:** Se ci sono sempre lettori, gli scrittori non riescono mai a scrivere.

### Soluzioni

#### 1. Fair Scheduling

```python
import threading

class FairLock:
    def __init__(self):
        self.lock = threading.Lock()
        self.waiting = []
        self.current = None
    
    def acquire(self):
        thread_id = threading.current_thread().ident
        with self.lock:
            self.waiting.append(thread_id)
        
        # Attende il proprio turno
        while self.current != thread_id:
            time.sleep(0.001)
    
    def release(self):
        with self.lock:
            if self.waiting:
                self.current = self.waiting.pop(0)
```

#### 2. Aging

Aumentare la prioritÃ  di thread che aspettano troppo:

```python
class Task:
    def __init__(self, priority):
        self.base_priority = priority
        self.wait_time = 0
    
    def get_effective_priority(self):
        # PrioritÃ  aumenta con il tempo di attesa
        return self.base_priority + self.wait_time * 0.1
```

---

## Livelock

### Definizione

**Livelock** Ã¨ una situazione simile al deadlock, ma con una differenza cruciale: i processi/thread **continuano ad eseguire** e cambiare stato in risposta agli altri, ma **senza fare progressi reali** verso il completamento. Ãˆ come essere "bloccati nella cortesia".

### Analogia: Le Persone Cortesi

Immagina due persone che si incontrano in un corridoio stretto:

```
Corridoio:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ‘¤A          ğŸ‘¤B    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tempo 0: A va a sinistra, B va a destra
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ğŸ‘¤A    ğŸ‘¤B       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tempo 1: Entrambi vedono che vanno a sbattere
        A va a destra, B va a sinistra (per cortesia)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ‘¤A          ğŸ‘¤B    â”‚  â† Stessa situazione!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tempo 2: Di nuovo si evitano
        A va a sinistra, B va a destra
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ğŸ‘¤A    ğŸ‘¤B       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

... questo continua all'infinito! (LIVELOCK)
```

Entrambi si muovono attivamente, ma nessuno passa mai!

### Differenze tra Deadlock, Starvation e Livelock

**Tabella comparativa:**

| Caratteristica | Deadlock | Starvation | Livelock |
|----------------|----------|------------|----------|
| **Stato dei processi** | Bloccati (waiting) | In attesa | Attivi (running) |
| **Cambiano stato?** | No | No | SÃ¬, continuamente |
| **Fanno progressi?** | No | Eventualmente sÃ¬ | No |
| **Utilizzo CPU** | 0% | 0-100% (altri usano) | 100% (sprecata!) |
| **Facile da rilevare?** | Moderato | Difficile | Molto difficile |
| **Esempio vita reale** | Incrocio bloccato | Fila infinita | Balletto cortese |

### Visualizzazione degli Stati

```
Deadlock:
Thread A: âš«â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  (bloccato, non cambia stato)
Thread B: âš«â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  (bloccato, non cambia stato)
CPU:      â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  (idle)

Starvation:
Thread A: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (esegue)
Thread B: âš«â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  (aspetta, non esegue mai)
CPU:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (usata da A)

Livelock:
Thread A: â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘  (cambia stato continuamente)
Thread B: â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—â—‘â—  (cambia stato continuamente)
CPU:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (100% usata MA senza progressi!)
```

### PerchÃ© Ã¨ Difficile da Rilevare?

1. **I thread sono attivi**: Sembrano funzionare normalmente
2. **CPU al 100%**: Il sistema sembra occupato
3. **Nessun errore**: Non ci sono eccezioni o timeout
4. **Cambiamenti di stato**: I log mostrano attivitÃ 
5. **Solo il risultato finale manca**: Il lavoro non si completa mai

### Esempio: Persone Cortesi

```python
import threading
import time

class Person:
    def __init__(self, name):
        self.name = name
        self.side = "left"
    
    def pass_through(self, other):
        while self.side == other.side:
            print(f"{self.name}: stepping to {'right' if self.side == 'left' else 'left'}")
            self.side = "right" if self.side == "left" else "left"
            time.sleep(0.1)
        
        print(f"{self.name}: passed!")

# Due persone che si spostano continuamente
# ma sempre dalla stessa parte â†’ LIVELOCK
```

### Esempio: Retry Simultaneo

```python
import threading
import time

def task_with_retry(id, resource):
    while True:
        if resource.try_acquire():
            try:
                do_work()
                break
            finally:
                resource.release()
        else:
            # Entrambi i thread rilasciano e riprovano simultaneamente
            time.sleep(0.1)  # Stesso tempo di attesa â†’ LIVELOCK
```

### Soluzione: Randomized Backoff

```python
import random
import time

def task_with_random_retry(id, resource):
    while True:
        if resource.try_acquire():
            try:
                do_work()
                break
            finally:
                resource.release()
        else:
            # Backoff randomico previene livelock
            time.sleep(random.uniform(0.1, 0.5))
```

---

## AtomicitÃ  delle Operazioni

### Definizione

Un'operazione Ã¨ **atomica** (dal greco "atomos" = indivisibile) se appare come un'unica operazione indivisibile dal punto di vista degli altri thread: viene eseguita **completamente** o **non viene eseguita affatto**, senza stati intermedi osservabili.

### Analogia: Transazione Bancaria

Considera un trasferimento di denaro:

```
NON Atomico (MALE):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Leggi saldo account A: 1000â‚¬   â”‚ â† Visibile
â”‚ 2. Sottrai 100â‚¬ da A: 900â‚¬        â”‚ â† Visibile  
â”‚ 3. Leggi saldo account B: 500â‚¬    â”‚ â† Visibile
â”‚ 4. Aggiungi 100â‚¬ a B: 600â‚¬        â”‚ â† Visibile
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Problema: tra step 2 e 4, i 100â‚¬ "scompaiono"!

Atomico (BENE):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ transfer(A, B, 100â‚¬)               â”‚ â† Singola operazione
â”‚ [internamente: A-=100, B+=100]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Dall'esterno: o succede tutto o niente
```

### ProprietÃ  delle Operazioni Atomiche

#### 1. All-or-Nothing (Tutto o Niente)
```
Atomica:     â–ˆâ–ˆâ–ˆâ–ˆ (successo completo)
          O
             âš« (fallimento completo)

Non Atomica: â–ˆâ–ˆâ–‘â–‘ (stato intermedio) â† PROBLEMA!
```

#### 2. IndivisibilitÃ 
Nessun altro thread puÃ² osservare uno stato intermedio:

```
Thread A: [Operazione Atomica]
Thread B: Vede solo â”€â”€beforeâ”€â”€ o â”€â”€afterâ”€â”€
          Non puÃ² vedere stati intermedi
```

#### 3. Isolamento
L'operazione non puÃ² essere interrotta nel mezzo:

```
Atomica:
Thread A: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] â† Non interrompibile
Thread B:                  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

Non Atomica:
Thread A: [â–ˆâ–ˆâ–ˆâ–‘        ]
Thread B:     â–ˆâ–ˆâ–ˆâ–ˆ â† Interferenza!
Thread A:        â–‘â–ˆâ–ˆâ–ˆ]
```

### PerchÃ© Servono Operazioni Atomiche?

Consideriamo l'operazione `x++` in dettaglio:

```c
// Codice C: x++
x = x + 1;

// Assembly (semplificato):
LOAD R1, [x]      ; R1 = valore di x
ADD R1, 1         ; R1 = R1 + 1
STORE [x], R1     ; x = R1

// Sono 3 istruzioni separate!
```

**Problema con 2 thread:**

```
Scenario 1 (corretto per fortuna):
T1: LOAD(10) â†’ ADD(11) â†’ STORE(11)
T2:                                    LOAD(11) â†’ ADD(12) â†’ STORE(12)
Risultato: 12 âœ“

Scenario 2 (race condition):
T1: LOAD(10) â†’ ADD(11) â†’ STORE(11)
T2: LOAD(10) â†’ ADD(11) â†’ STORE(11)
Risultato: 11 âœ— (dovrebbe essere 12!)

Scenario 3 (ancora peggio):
T1: LOAD(10)
T2:          LOAD(10) â†’ ADD(11) â†’ STORE(11)
T1:                                           ADD(11) â†’ STORE(11)
Risultato: 11 âœ— (il lavoro di T2 Ã¨ sovrascritto!)
```

### Livelli di AtomicitÃ 

#### 1. Hardware Level (CPU)
Le CPU forniscono istruzioni atomiche native:

```assembly
; x86/x64
LOCK INC [memory]     ; Incremento atomico
LOCK ADD [mem], value ; Addizione atomica
CMPXCHG              ; Compare-and-Exchange atomico
XCHG                 ; Exchange atomico

; ARM
LDREX / STREX        ; Load/Store Exclusive
```

Il prefisso `LOCK` blocca il bus di memoria, garantendo atomicitÃ .

#### 2. Software Level (Librerie)
Linguaggi forniscono astrazioni:

```java
// Java
AtomicInteger counter = new AtomicInteger(0);
counter.incrementAndGet();  // Atomico

// C++ 
std::atomic<int> counter{0};
counter++;  // Atomico

// Python (con lock interno)
import threading
lock = threading.Lock()
with lock:  # "Pseudo-atomico"
    counter += 1
```

#### 3. Database Level (Transazioni)
```sql
BEGIN TRANSACTION;
  UPDATE accounts SET balance = balance - 100 WHERE id = 1;
  UPDATE accounts SET balance = balance + 100 WHERE id = 2;
COMMIT;  -- Atomico: tutto o niente
```

### Operazioni Non Atomiche

```python
# NON atomico in Python
counter += 1

# NON atomico in Java
count++;

# NON atomico in C
x = x + 1;
```

### Operazioni Atomiche Hardware

Le CPU forniscono istruzioni atomiche:

- **CAS** (Compare-And-Swap)
- **TAS** (Test-And-Set)
- **FAA** (Fetch-And-Add)
- **LL/SC** (Load-Linked/Store-Conditional)

#### Compare-And-Swap (CAS)

```c
bool compare_and_swap(int *ptr, int expected, int new_value) {
    // Atomico!
    if (*ptr == expected) {
        *ptr = new_value;
        return true;
    }
    return false;
}
```

**Uso per lock-free increment:**
```c
void atomic_increment(int *counter) {
    int old_value, new_value;
    do {
        old_value = *counter;
        new_value = old_value + 1;
    } while (!compare_and_swap(counter, old_value, new_value));
}
```

### Atomic Types

#### Java

```java
import java.util.concurrent.atomic.*;

AtomicInteger counter = new AtomicInteger(0);
counter.incrementAndGet();  // Atomico
counter.compareAndSet(0, 1);  // CAS

AtomicReference<String> ref = new AtomicReference<>("initial");
ref.compareAndSet("initial", "updated");
```

#### Python (con lock implicito)

```python
import threading

class AtomicInteger:
    def __init__(self, value=0):
        self._value = value
        self._lock = threading.Lock()
    
    def increment(self):
        with self._lock:
            self._value += 1
            return self._value
    
    def get(self):
        with self._lock:
            return self._value
```

#### C++ (std::atomic)

```cpp
#include <atomic>

std::atomic<int> counter(0);
counter++;  // Atomico
counter.fetch_add(1);  // Atomico

// CAS
int expected = 0;
counter.compare_exchange_strong(expected, 1);
```

---

## Priority Inversion

### Definizione

**Priority inversion** (inversione di prioritÃ ) Ã¨ una situazione paradossale nei sistemi real-time dove un task ad **alta prioritÃ ** Ã¨ costretto ad aspettare un task a **bassa prioritÃ **, invertendo di fatto il sistema di prioritÃ  progettato nel sistema.

### Il Problema Fondamentale

In un sistema con prioritÃ , ci aspettiamo:
```
âœ“ Alta prioritÃ  esegue PRIMA della bassa prioritÃ 
âœ— MA con priority inversion: alta prioritÃ  BLOCCATA da bassa!
```

### Analogia: L'Autostrada

Immagina una autostrada a 3 corsie:

```
Corsia Veloce (High):    ğŸš—ğŸ’¨  (Ferrari - prioritÃ  10)
Corsia Normale (Medium): ğŸš™    (Auto normale - prioritÃ  5)  
Corsia Lenta (Low):      ğŸš›    (Camion - prioritÃ  1)

Scenario normale:
Ferrari supera tutti âœ“

Scenario con Priority Inversion:
ğŸš› ha un carico che la ğŸš— deve ritirare
ğŸš— deve aspettare ğŸš›
Ma ğŸš› Ã¨ bloccato nel traffico da ğŸš™
Risultato: ğŸš— (prioritÃ  10) aspetta ğŸš™ (prioritÃ  5)!
```

### Caso Reale: Mars Pathfinder (1997)

**Storia vera**: La missione Mars Pathfinder della NASA ha subito reset improvvisi a causa di priority inversion!

```
Sistema Pathfinder:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ High Priority: Bus Management Task      â”‚ â† Critico per il sistema
â”‚ Medium Priority: Comunicazione          â”‚
â”‚ Low Priority: Meteorological Data       â”‚ â† Raccolta dati meteo
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problema:
1. Low priority acquisisce un mutex condiviso
2. High priority cerca lo stesso mutex â†’ BLOCCATO
3. Medium priority esegue (non serve il mutex)
4. Low priority Ã¨ preempted da Medium
5. High priority aspetta Low che non puÃ² eseguire!
6. Watchdog rileva timeout â†’ SYSTEM RESET
```

**Soluzione applicata**: Priority inheritance (aggiornamento software inviato dalla Terra!)

### Scenario Classico Dettagliato

```
Task PrioritÃ :
H (High):   prioritÃ  10 - Critical
M (Medium): prioritÃ  5  - Normal  
L (Low):    prioritÃ  1  - Background
```

**Timeline completa dell'inversione:**

```
Time: 0ms      50ms    100ms   150ms   200ms   250ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
L:    â”€[LOCK]â”€ â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–  [UNLOCK]â”€
                â†‘                        â†‘
                â”‚ Preempted              â”‚ Finalmente!
                â”‚                        â”‚
M:              â””â”€â”€[RUNNING]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                   
H:              â”€â”€[BLOCKED waiting for lock]â”€â”€[RUN]
                   â³â³â³â³â³â³â³â³â³â³â³â³â³â³
                   â†‘
                   Priority Inversion Zone!
                   H aspetta L, ma L non puÃ² eseguire
```

**Dettaglio degli eventi:**

```
T=0ms:   L acquisisce il lock
         L inizia elaborazione

T=50ms:  H si risveglia (evento critico)
         H cerca di acquisire il lock
         H va in WAIT (lock posseduto da L)

T=51ms:  M si risveglia  
         M ha prioritÃ  > L â†’ PREEMPTS L
         M inizia a eseguire

T=50-200ms: âš ï¸ PRIORITY INVERSION
         H (prioritÃ  10) Ã¨ bloccato
         M (prioritÃ  5) sta eseguendo  
         L (prioritÃ  1) Ã¨ preempted
         
         Dovrebbe essere: H > M > L
         RealtÃ :          M > (H waiting) > (L preempted)

T=200ms: M finisce
         L riprende esecuzione

T=250ms: L rilascia lock
         H finalmente puÃ² eseguire!
```

### Effetti dell'Inversione

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tempo di Risposta del Task H                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ideale:      [trigger]â”€5msâ”€[done]              â”‚
â”‚                                                  â”‚
â”‚ Con Inversion: [trigger]â”€200msâ”€[done]          â”‚
â”‚                   â””â”€â”€ Inaccettabile!             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Bounded Priority Inversion:
  H aspetta al massimo il tempo di esecuzione di L

Unbounded Priority Inversion:
  H aspetta L + tutti i task a media prioritÃ 
  PuÃ² durare indefinitamente!
```

### Esempio

```python
import threading
import time

lock = threading.Lock()

def low_priority():
    with lock:
        print("Low: acquired lock")
        time.sleep(2)  # Lungo lavoro
        print("Low: released lock")

def medium_priority():
    time.sleep(0.1)
    print("Medium: running (preempts low)")
    time.sleep(1.5)
    print("Medium: done")

def high_priority():
    time.sleep(0.2)
    print("High: trying to acquire lock")
    with lock:  # Bloccato da Low, che Ã¨ preempted da Medium!
        print("High: acquired lock")

# High deve attendere sia Low che Medium
```

### Soluzioni

#### 1. Priority Inheritance

Il task che detiene il lock eredita temporaneamente la prioritÃ  del task in attesa:

```
L holds lock, priority = 1
H waits for lock, priority = 10
â†’ L inherits priority 10 until it releases lock
```

#### 2. Priority Ceiling

Ogni lock ha una prioritÃ  massima; chi acquisisce il lock ottiene quella prioritÃ :

```python
class PriorityCeilingLock:
    def __init__(self, ceiling_priority):
        self.lock = threading.Lock()
        self.ceiling = ceiling_priority
    
    def acquire(self):
        # Eleva la prioritÃ  al ceiling
        old_priority = get_current_priority()
        set_priority(self.ceiling)
        self.lock.acquire()
        return old_priority
    
    def release(self, old_priority):
        self.lock.release()
        set_priority(old_priority)
```

---

## Problemi Classici

### 1. Produttore-Consumatore

**Problema:** Sincronizzare produttore e consumatore con buffer limitato.

```python
import threading
import queue
import time
import random

buffer = queue.Queue(maxsize=5)

def producer():
    for i in range(10):
        item = f"item-{i}"
        buffer.put(item)  # Blocca se pieno
        print(f"Produced: {item}")
        time.sleep(random.random())

def consumer():
    while True:
        item = buffer.get()  # Blocca se vuoto
        print(f"Consumed: {item}")
        time.sleep(random.random())
        buffer.task_done()

threading.Thread(target=producer).start()
threading.Thread(target=consumer, daemon=True).start()
```

### 2. Lettori-Scrittori

**Problema:** PiÃ¹ lettori simultanei OK, ma scrittori in mutua esclusione.

```python
import threading

class ReadWriteLock:
    def __init__(self):
        self.readers = 0
        self.lock = threading.Lock()
        self.write_lock = threading.Lock()
    
    def acquire_read(self):
        with self.lock:
            self.readers += 1
            if self.readers == 1:
                self.write_lock.acquire()
    
    def release_read(self):
        with self.lock:
            self.readers -= 1
            if self.readers == 0:
                self.write_lock.release()
    
    def acquire_write(self):
        self.write_lock.acquire()
    
    def release_write(self):
        self.write_lock.release()
```

### 3. Barbiere Addormentato

**Problema:** Sincronizzare barbiere e clienti con sala d'attesa limitata.

```python
import threading
import time
import random

waiting_room = threading.Semaphore(3)  # 3 sedie
barber_ready = threading.Semaphore(0)
customer_ready = threading.Semaphore(0)
mutex = threading.Lock()
waiting_customers = 0

def barber():
    while True:
        customer_ready.acquire()  # Attende cliente
        with mutex:
            global waiting_customers
            waiting_customers -= 1
        barber_ready.release()  # Segnala pronto
        print("Barber: cutting hair")
        time.sleep(random.uniform(0.5, 1.5))

def customer(id):
    global waiting_customers
    with mutex:
        if waiting_customers < 3:
            waiting_customers += 1
            print(f"Customer {id}: waiting")
            customer_ready.release()
        else:
            print(f"Customer {id}: leaving (full)")
            return
    
    barber_ready.acquire()  # Attende barbiere
    print(f"Customer {id}: getting haircut")
```

---

## Tecniche di Prevenzione

### 1. Evitare Stato Condiviso

```python
# BAD: stato condiviso
global_counter = 0

def worker():
    global global_counter
    global_counter += 1

# GOOD: nessuno stato condiviso
def worker(counter_queue):
    result = do_work()
    counter_queue.put(result)
```

### 2. ImmutabilitÃ 

```python
# Oggetti immutabili sono inherently thread-safe
from collections import namedtuple

Point = namedtuple('Point', ['x', 'y'])
p = Point(10, 20)
# p.x = 30  # Errore!
```

### 3. Thread-Local Storage

```python
import threading

# Ogni thread ha la propria copia
thread_local = threading.local()

def worker():
    thread_local.value = get_thread_id()
    # Nessuna interferenza tra thread
```

### 4. Lock-Free Data Structures

```python
# Esempio: queue lock-free
from queue import Queue

q = Queue()  # Implementazione lock-free in CPython
q.put(item)  # Thread-safe senza lock espliciti
```

---

## Esercizi

### Esercizio 1: Race Condition Detection
Scrivere un programma che dimostra una race condition e poi correggerla.

### Esercizio 2: Deadlock Prevention
Implementare il problema dei filosofi a cena usando lock ordering.

### Esercizio 3: Readers-Writers
Implementare una soluzione al problema readers-writers che previene starvation degli scrittori.

### Esercizio 4: Atomic Counter
Creare un contatore thread-safe usando solo operazioni atomiche (senza lock).

---

## Tool per Debugging

### 1. Thread Sanitizer (C/C++)

```bash
gcc -fsanitize=thread -g program.c
./a.out
```

### 2. Helgrind (Valgrind)

```bash
valgrind --tool=helgrind ./program
```

### 3. Java Thread Dump

```bash
jstack <pid> > thread_dump.txt
```

### 4. Python Threading Debug

```python
import sys
sys.settrace(threading._trace_hook)
```

---

## Best Practices

1. **Minimizzare le sezioni critiche**
   ```python
   # BAD: lock troppo ampio
   with lock:
       data = fetch_data()
       result = process(data)
       save(result)
   
   # GOOD: lock minimo
   data = fetch_data()
   result = process(data)
   with lock:
       save(result)
   ```

2. **Evitare nested locks**
   ```python
   # BAD
   with lock_a:
       with lock_b:  # Possibile deadlock
           do_work()
   
   # GOOD: usare un singolo lock
   with combined_lock:
       do_work()
   ```

3. **Timeout sui lock**
   ```python
   if lock.acquire(timeout=5):
       try:
           do_work()
       finally:
           lock.release()
   else:
       handle_timeout()
   ```

4. **Documentare l'ordine dei lock**
   ```python
   # Lock order: lock_a â†’ lock_b â†’ lock_c
   # ALWAYS acquire in this order!
   ```

---

## Risorse Aggiuntive

- **Libri:**
  - "The Art of Multiprocessor Programming"
  - "Java Concurrency in Practice"
  - "Operating System Concepts"

- **Tool:**
  - ThreadSanitizer
  - Valgrind/Helgrind
  - Intel Inspector
  - JProfiler

---

**Precedente:** [02 - Architetture Hardware](02-architetture-hardware.md)  
**Prossimo:** [Modulo 2 - Processi in Linux](../Modulo2/README.md)
